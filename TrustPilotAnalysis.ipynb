{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar librerías necesarias\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "from datetime import datetime\n",
    "import os\n",
    "import glob\n",
    "import pickle\n",
    "from typing import Dict, List, Optional, Tuple\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuración de API\n",
    "OPENROUTER_API_KEY = \"\"  # ⚠️ AÑADIR TU API KEY AQUÍ - Obtener de https://openrouter.ai/keys\n",
    "OPENROUTER_API_URL = \"https://openrouter.ai/api/v1/chat/completions\"\n",
    "\n",
    "# Modelo recomendado (puedes cambiar según necesidades y presupuesto)\n",
    "MODEL = \"google/gemini-2.5-flash\"  # Rápido y económico\n",
    "# Alternativas: \"openai/gpt-3.5-turbo\", \"meta-llama/llama-3-8b-instruct\"\n",
    "\n",
    "# Headers para las peticiones\n",
    "headers = {\n",
    "    \"Authorization\": f\"Bearer {OPENROUTER_API_KEY}\",\n",
    "    \"Content-Type\": \"application/json\",\n",
    "    \"HTTP-Referer\": \"http://localhost:8888\",  # Requerido por OpenRouter\n",
    "    \"X-Title\": \"TrustPilot Analysis\"\n",
    "}\n",
    "\n",
    "# Definir los campos esperados en la respuesta del modelo (en orden)\n",
    "CAMPOS_ANALISIS = [\n",
    "    \"language\", \"sentiment\", \"sentiment_score\", \"emotion\", \"emotion_intensity\", \"customer_gender\",\n",
    "    \"main_topic\", \"keywords\", \"customer_type\", \"tourist_type\", \"group_type\"\n",
    "]\n",
    "\n",
    "# Variables globales para los nombres de las columnas (se asignarán dinámicamente)\n",
    "REVIEW_TEXT_COL = None\n",
    "CUSTOMER_NAME_COL = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar el CSV con las reseñas\n",
    "df = pd.read_csv('./test.csv', encoding='utf-8-sig')\n",
    "\n",
    "# Limpiar nombres de columnas (quitar espacios extra)\n",
    "df.columns = df.columns.str.strip()\n",
    "\n",
    "# Mostrar todas las columnas para identificar correctamente\n",
    "print(f\"Total de reseñas: {len(df)}\")\n",
    "print(f\"Columnas en el CSV:\")\n",
    "for i, col in enumerate(df.columns):\n",
    "    print(f\"  {i}: '{col}' (longitud: {len(col)})\")\n",
    "\n",
    "# Buscar la columna de review_text (puede tener nombre ligeramente diferente)\n",
    "texto_columnas = [col for col in df.columns if 'review' in col.lower() and 'text' in col.lower()]\n",
    "nombre_columnas = [col for col in df.columns if 'customer' in col.lower() and 'name' in col.lower()]\n",
    "\n",
    "print(f\"\\nColumnas que contienen 'review' y 'text': {texto_columnas}\")\n",
    "print(f\"Columnas que contienen 'customer' y 'name': {nombre_columnas}\")\n",
    "\n",
    "# Si encontramos las columnas, proceder con la limpieza\n",
    "if texto_columnas and nombre_columnas:\n",
    "    # Asignar variables globales\n",
    "    REVIEW_TEXT_COL = texto_columnas[0]\n",
    "    CUSTOMER_NAME_COL = nombre_columnas[0]\n",
    "    \n",
    "    print(f\"\\nUsando columnas:\")\n",
    "    print(f\"- Texto de reseña: '{REVIEW_TEXT_COL}'\")\n",
    "    print(f\"- Nombre del cliente: '{CUSTOMER_NAME_COL}'\")\n",
    "    \n",
    "    # Limpiar datos: eliminar filas con review_text vacío o nulo\n",
    "    df_original_len = len(df)\n",
    "    df = df.dropna(subset=[REVIEW_TEXT_COL])  # Eliminar filas con texto nulo\n",
    "    df = df[df[REVIEW_TEXT_COL].astype(str).str.strip() != '']  # Eliminar filas con texto vacío\n",
    "    \n",
    "    print(f\"\\nLimpieza de datos:\")\n",
    "    print(f\"- Reseñas originales: {df_original_len}\")\n",
    "    print(f\"- Reseñas después de limpieza: {len(df)}\")\n",
    "    print(f\"- Reseñas eliminadas: {df_original_len - len(df)}\")\n",
    "    \n",
    "    # Inicializar la columna 'analyzed' si no existe\n",
    "    if 'analyzed' not in df.columns:\n",
    "        df['analyzed'] = False\n",
    "        \n",
    "    print(f\"- Reseñas ya analizadas: {df['analyzed'].sum()}\")\n",
    "    print(f\"- Reseñas pendientes de analizar: {(df['analyzed'] == False).sum()}\")\n",
    "    \n",
    "else:\n",
    "    print(\"\\n❌ No se encontraron las columnas de texto de reseña o nombre del cliente\")\n",
    "    print(\"Por favor revisa el archivo CSV\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crear_prompt_analisis(review_text, customer_name):\n",
    "    \"\"\"Crea el prompt para analizar una reseña\"\"\"\n",
    "    \n",
    "    prompt = f\"\"\"\n",
    "Eres un analizador especializado en evaluación de reseñas turísticas y análisis de sentimientos. Para cada texto que recibas, deberás analizar y proporcionar la siguiente información separada por el delimitador \"|\":\n",
    "\n",
    "RESEÑA A ANALIZAR:\n",
    "Texto: {review_text}\n",
    "Cliente: {customer_name}\n",
    "\n",
    "ANÁLISIS REQUERIDO (responde cada campo separado por \"|\"):\n",
    "\n",
    "0. Language: Clasifica como \"es\", \"en\", \"fr\", \"de\", \"it\", \"pt\", \"nl\", \"ru\", \"tr\", \"ar\", \"zh\", \"ja\", \"ko\", \"other\"\n",
    "1. Sentiment: Clasifica como \"Positivo\", \"Negativo\" o \"Neutro\"\n",
    "2. Sentiment_score: Evalúa en escala de -1 a +1 (-1=extremadamente negativo, 0=neutro, +1=extremadamente positivo)\n",
    "3. Emotion: Identifica una emoción (joy, surprise, neutral, sadness, disgust, anger, fear)\n",
    "4. Emotion_intensity: Intensidad de 1-5 (1=muy leve, 5=muy intensa)\n",
    "5. Customer_gender: Basado en el nombre (masculino, femenino, unknown)\n",
    "6. Topic: Tema principal (Atención al cliente, Limpieza, Instalaciones, Relación calidad-precio, Servicios, Ubicación, Ética y sostenibilidad, Check-in y Check-out, Comodidad y descanso, Oferta gastronómica, Facilidad de reserva y accesibilidad digital, Animación y actividades, Seguridad)\n",
    "7. Keywords: 3-5 términos relevantes separados por comas SIN espacios\n",
    "8. Customer_type: Promotor, Leal, Neutral, Crítico, Oportunista\n",
    "9. Tourist_type: Turista de ocio, cultural, naturaleza, aventura, compras, espiritual/religioso, gastronómico, deportivo, wellness, solidario/voluntario\n",
    "10. Group_type: familiar, amigos, pareja, solitario, grupo organizado\n",
    "\n",
    "FORMATO DE RESPUESTA:\n",
    "Responde ÚNICAMENTE con los valores separados por \"|\" en el orden exacto listado arriba.\n",
    "Si no puedes determinar algún campo, usa \"unknown\".\n",
    "NO incluyas espacios antes o después de los pipes.\n",
    "\n",
    "Ejemplo: Positivo|0.8|joy|4|femenino|Atención al cliente|excelente,servicio,amable|Promotor|Turista de ocio|pareja\n",
    "\"\"\"\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analizar_con_llm(review_text, customer_name, max_retries=3):\n",
    "    \"\"\"Llama a OpenRouter para analizar una reseña\"\"\"\n",
    "    \n",
    "    prompt = crear_prompt_analisis(review_text, customer_name)\n",
    "    \n",
    "    payload = {\n",
    "        \"model\": MODEL,\n",
    "        \"messages\": [\n",
    "            {\"role\": \"system\", \"content\": \"Eres un experto en análisis de reseñas de viajes. Respondes SOLO con los valores separados por |.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        \"temperature\": 0.1,  # Baja temperatura para respuestas consistentes\n",
    "        \"max_tokens\": 500\n",
    "    }\n",
    "    \n",
    "    for intento in range(max_retries):\n",
    "        try:\n",
    "            response = requests.post(\n",
    "                OPENROUTER_API_URL,\n",
    "                headers=headers,\n",
    "                json=payload,\n",
    "                timeout=30\n",
    "            )\n",
    "            \n",
    "            if response.status_code == 200:\n",
    "                result = response.json()\n",
    "                content = result['choices'][0]['message']['content']\n",
    "                \n",
    "                print(f\"Respuesta del modelo: {content}\")  # Para depuración\n",
    "                \n",
    "                if not content.strip():\n",
    "                    print(\"Respuesta vacía de la API\")\n",
    "                    return None\n",
    "                \n",
    "                # Limpiar posibles markdown o espacios extra\n",
    "                if \"```\" in content:\n",
    "                    # Extraer contenido entre markdown\n",
    "                    lines = content.split('\\n')\n",
    "                    for line in lines:\n",
    "                        if '|' in line and not line.strip().startswith('```'):\n",
    "                            content = line.strip()\n",
    "                            break\n",
    "                \n",
    "                content = content.strip()\n",
    "                \n",
    "                # Dividir por el delimitador pipe\n",
    "                valores = [v.strip() for v in content.split(\"|\")]\n",
    "                \n",
    "                # Verificar que tenemos el número correcto de campos\n",
    "                if len(valores) != len(CAMPOS_ANALISIS):\n",
    "                    print(f\"La respuesta no tiene el número correcto de campos: {len(valores)} vs {len(CAMPOS_ANALISIS)}\")\n",
    "                    print(f\"Valores recibidos: {valores}\")\n",
    "                    return None\n",
    "                \n",
    "                # Crear diccionario con los resultados\n",
    "                resultado = dict(zip(CAMPOS_ANALISIS, valores))\n",
    "                return resultado\n",
    "            \n",
    "            elif response.status_code == 429:  # Rate limit\n",
    "                time.sleep(2 ** intento)  # Exponential backoff\n",
    "                continue\n",
    "            \n",
    "            else:\n",
    "                print(f\"Error API: {response.status_code} - {response.text}\")\n",
    "                return None\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Error en petición: {e}\")\n",
    "            if intento < max_retries - 1:\n",
    "                time.sleep(1)\n",
    "    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def procesar_reseñas_batch(df, batch_size=10, start_index=0):\n",
    "    \"\"\"Procesa las reseñas en lotes para evitar límites de rate\"\"\"\n",
    "    \n",
    "    global REVIEW_TEXT_COL, CUSTOMER_NAME_COL\n",
    "    \n",
    "    if REVIEW_TEXT_COL is None or CUSTOMER_NAME_COL is None:\n",
    "        print(\"❌ Error: Las columnas de texto y nombre no han sido identificadas\")\n",
    "        return [], []\n",
    "    \n",
    "    # Filtrar solo reseñas no analizadas (ya limpiamos los datos vacíos en la carga)\n",
    "    df_pendientes = df[df['analyzed'] == False].iloc[start_index:]\n",
    "    \n",
    "    print(f\"Reseñas pendientes de analizar: {len(df_pendientes)}\")\n",
    "    \n",
    "    resultados = []\n",
    "    errores = []\n",
    "    \n",
    "    # Procesar en lotes\n",
    "    for i in tqdm(range(0, len(df_pendientes), batch_size), desc=\"Procesando lotes\"):\n",
    "        batch = df_pendientes.iloc[i:i+batch_size]\n",
    "        \n",
    "        for idx, row in batch.iterrows():\n",
    "            # Analizar reseña usando nombres de columnas dinámicos\n",
    "            resultado = analizar_con_llm(\n",
    "                row[REVIEW_TEXT_COL], \n",
    "                row[CUSTOMER_NAME_COL]\n",
    "            )\n",
    "            \n",
    "            if resultado:\n",
    "                resultado['index'] = idx\n",
    "                resultados.append(resultado)\n",
    "            else:\n",
    "                errores.append({\n",
    "                    'index': idx,\n",
    "                    'review_id': row.get('review_id', 'N/A'),\n",
    "                    'error': 'No se pudo analizar'\n",
    "                })\n",
    "            \n",
    "            # Pequeña pausa entre peticiones\n",
    "            time.sleep(0.5)\n",
    "        \n",
    "        # Pausa más larga entre lotes\n",
    "        print(f\"Lote completado. Esperando antes del siguiente...\")\n",
    "        time.sleep(2)\n",
    "    \n",
    "    return resultados, errores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def actualizar_dataframe(df, resultados):\n",
    "    \"\"\"Actualiza el DataFrame con los resultados del análisis\"\"\"\n",
    "    \n",
    "    # Inicializar las columnas si no existen\n",
    "    for campo in CAMPOS_ANALISIS:\n",
    "        if campo not in df.columns:\n",
    "            df[campo] = None\n",
    "    \n",
    "    # Agregar columna 'analyzed' si no existe\n",
    "    if 'analyzed' not in df.columns:\n",
    "        df['analyzed'] = False\n",
    "    \n",
    "    # Actualizar con los resultados\n",
    "    for resultado in resultados:\n",
    "        idx = resultado['index']\n",
    "        \n",
    "        # Actualizar cada campo\n",
    "        for campo in CAMPOS_ANALISIS:\n",
    "            if campo in resultado:\n",
    "                df.loc[idx, campo] = resultado[campo]\n",
    "        \n",
    "        # Marcar como analizado\n",
    "        df.loc[idx, 'analyzed'] = True\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def guardar_progreso(df, filename_base='trustpilot_analyzed'):\n",
    "    \"\"\"Guarda el progreso del análisis\"\"\"\n",
    "    \n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    filename = f\"{filename_base}_{timestamp}.csv\"\n",
    "    \n",
    "    df.to_csv(filename, index=False, encoding='utf-8-sig')\n",
    "    print(f\"Progreso guardado en: {filename}\")\n",
    "    \n",
    "    # También guardar un backup del último estado\n",
    "    df.to_csv(f\"{filename_base}_latest.csv\", index=False, encoding='utf-8-sig')\n",
    "    \n",
    "    return filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analizar_trustpilot_reviews(csv_path, batch_size=10, max_reviews=None):\n",
    "    \"\"\"Función principal para analizar las reseñas\"\"\"\n",
    "    \n",
    "    # Cargar datos\n",
    "    print(\"📂 Cargando datos...\")\n",
    "    df = pd.read_csv(csv_path, encoding='utf-8-sig')\n",
    "    \n",
    "    # Limitar número de reseñas si se especifica\n",
    "    if max_reviews:\n",
    "        df = df.head(max_reviews)\n",
    "    \n",
    "    print(f\"📊 Total de reseñas a procesar: {len(df)}\")\n",
    "    \n",
    "    # Verificar API key\n",
    "    if not OPENROUTER_API_KEY or OPENROUTER_API_KEY == \"tu-api-key-aqui\":\n",
    "        print(\"❌ Error: Configura tu API key de OpenRouter\")\n",
    "        return None\n",
    "    \n",
    "    # Procesar reseñas\n",
    "    print(\"\\n🤖 Iniciando análisis con LLM...\")\n",
    "    resultados, errores = procesar_reseñas_batch(df, batch_size)\n",
    "    \n",
    "    # Actualizar DataFrame\n",
    "    print(f\"\\n✅ Análisis completado: {len(resultados)} reseñas\")\n",
    "    print(f\"❌ Errores: {len(errores)} reseñas\")\n",
    "    \n",
    "    df_actualizado = actualizar_dataframe(df, resultados)\n",
    "    \n",
    "    # Guardar resultados\n",
    "    filename = guardar_progreso(df_actualizado)\n",
    "    \n",
    "    # Mostrar estadísticas\n",
    "    print(\"\\n📈 Estadísticas del análisis:\")\n",
    "    if 'sentiment' in df_actualizado.columns:\n",
    "        print(f\"- Sentimientos: {df_actualizado['sentiment'].value_counts().to_dict()}\")\n",
    "    if 'main_topic' in df_actualizado.columns:\n",
    "        print(f\"- Temas principales: {df_actualizado['main_topic'].value_counts().to_dict()}\")\n",
    "    if 'tourist_type' in df_actualizado.columns:\n",
    "        print(f\"- Tipos de turista: {df_actualizado['tourist_type'].value_counts().to_dict()}\")\n",
    "    if 'emotion' in df_actualizado.columns:\n",
    "        print(f\"- Emociones: {df_actualizado['emotion'].value_counts().to_dict()}\")\n",
    "    \n",
    "    return df_actualizado, errores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configurar parámetros\n",
    "CSV_PATH = \"./test.csv\"  # Ajusta el nombre\n",
    "BATCH_SIZE = 10  # Reseñas por lote\n",
    "MAX_REVIEWS = 100  # None para procesar todas\n",
    "\n",
    "# Ejecutar análisis\n",
    "df_analizado, errores = analizar_trustpilot_reviews(\n",
    "    csv_path=CSV_PATH,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    max_reviews=MAX_REVIEWS\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# Crear visualizaciones básicas\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Solo ejecutar si df_analizado existe y tiene datos analizados\n",
    "if 'df_analizado' in locals() and df_analizado is not None:\n",
    "    # Configurar estilo\n",
    "    plt.style.use('seaborn-v0_8')\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "    # 1. Distribución de sentimientos\n",
    "    if 'sentiment' in df_analizado.columns:\n",
    "        df_analizado['sentiment'].value_counts().plot(kind='bar', ax=axes[0,0])\n",
    "        axes[0,0].set_title('Distribución de Sentimientos')\n",
    "    \n",
    "    # 2. Top 10 temas principales\n",
    "    if 'main_topic' in df_analizado.columns:\n",
    "        df_analizado['main_topic'].value_counts().head(10).plot(kind='barh', ax=axes[0,1])\n",
    "        axes[0,1].set_title('Top 10 Temas Principales')\n",
    "    \n",
    "    # 3. Tipos de turista\n",
    "    if 'tourist_type' in df_analizado.columns:\n",
    "        df_analizado['tourist_type'].value_counts().plot(kind='pie', ax=axes[1,0])\n",
    "        axes[1,0].set_title('Tipos de Turista')\n",
    "    \n",
    "    # 4. Emociones detectadas\n",
    "    if 'emotion' in df_analizado.columns:\n",
    "        df_analizado['emotion'].value_counts().plot(kind='bar', ax=axes[1,1])\n",
    "        axes[1,1].set_title('Emociones Detectadas')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No hay datos analizados para visualizar. Ejecuta primero el análisis.\")\n",
    "\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
