{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar librer√≠as necesarias\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "from datetime import datetime\n",
    "import os\n",
    "import glob\n",
    "import pickle\n",
    "from typing import Dict, List, Optional, Tuple\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuraci√≥n de API\n",
    "OPENROUTER_API_KEY = \"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\"  # Obtener de https://openrouter.ai/keys\n",
    "OPENROUTER_API_URL = \"https://openrouter.ai/api/v1/chat/completions\"\n",
    "\n",
    "# Modelo recomendado (puedes cambiar seg√∫n necesidades y presupuesto)\n",
    "MODEL = \"google/gemini-2.5-flash\"  # R√°pido y econ√≥mico\n",
    "# Alternativas: \"openai/gpt-3.5-turbo\", \"meta-llama/llama-3-8b-instruct\"\n",
    "\n",
    "# Headers para las peticiones\n",
    "headers = {\n",
    "    \"Authorization\": f\"Bearer {OPENROUTER_API_KEY}\",\n",
    "    \"Content-Type\": \"application/json\",\n",
    "    \"HTTP-Referer\": \"http://localhost:8888\",  # Requerido por OpenRouter\n",
    "    \"X-Title\": \"TrustPilot Analysis\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar el CSV con las rese√±as\n",
    "df = pd.read_csv('', encoding='utf-8-sig')\n",
    "\n",
    "# Verificar columnas vac√≠as\n",
    "columnas_analizar = ['language', 'sentiment', 'emotion', 'customer_gender', \n",
    "                     'main_topic', 'keywords', 'tourist_type', 'group_type']\n",
    "\n",
    "print(f\"Total de rese√±as: {len(df)}\")\n",
    "print(f\"Rese√±as con texto: {df['review_text'].notna().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crear_prompt_analisis(review_text, customer_name):\n",
    "    \"\"\"Crea el prompt para analizar una rese√±a\"\"\"\n",
    "    \n",
    "    prompt = f\"\"\"\n",
    "Eres un analizador especializado en evaluaci√≥n de rese√±as tur√≠sticas y an√°lisis de sentimientos. Para cada texto que recibas, deber√°s analizar y proporcionar la siguiente informaci√≥n separada por el delimitador \"|\":\n",
    "\n",
    "RESE√ëA A ANALIZAR:\n",
    "Texto: {review_text}\n",
    "Cliente: {customer_name}\n",
    "\n",
    "AN√ÅLISIS REQUERIDO (responde cada campo separado por \"|\"):\n",
    "\n",
    "1. Sentiment: Clasifica como \"Positivo\", \"Negativo\" o \"Neutro\"\n",
    "2. Sentiment_score: Eval√∫a en escala de -1 a +1 (-1=extremadamente negativo, 0=neutro, +1=extremadamente positivo)\n",
    "3. Emotion: Identifica una emoci√≥n (joy, surprise, neutral, sadness, disgust, anger, fear)\n",
    "4. Emotion_intensity: Intensidad de 1-5 (1=muy leve, 5=muy intensa)\n",
    "5. Customer_gender: Basado en el nombre (masculino, femenino, unknown)\n",
    "6. Topic: Tema principal (Atenci√≥n al cliente, Limpieza, Instalaciones, Relaci√≥n calidad-precio, Servicios, Ubicaci√≥n, √âtica y sostenibilidad, Check-in y Check-out, Comodidad y descanso, Oferta gastron√≥mica, Facilidad de reserva y accesibilidad digital, Animaci√≥n y actividades, Seguridad)\n",
    "7. Keywords: 3-5 t√©rminos relevantes separados por comas SIN espacios\n",
    "8. Customer_type: Promotor, Leal, Neutral, Cr√≠tico, Oportunista\n",
    "9. Tourist_type: Turista de ocio, cultural, naturaleza, aventura, compras, espiritual/religioso, gastron√≥mico, deportivo, wellness, solidario/voluntario\n",
    "10. Group_type: familiar, amigos, pareja, solitario, grupo organizado\n",
    "\n",
    "FORMATO DE RESPUESTA:\n",
    "Responde √öNICAMENTE con los valores separados por \"|\" en el orden exacto listado arriba.\n",
    "Si no puedes determinar alg√∫n campo, usa \"unknown\".\n",
    "NO incluyas espacios antes o despu√©s de los pipes.\n",
    "\n",
    "Ejemplo: Positivo|0.8|joy|4|femenino|Atenci√≥n al cliente|excelente,servicio,amable|Promotor|Turista de ocio|pareja\n",
    "\"\"\"\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analizar_con_llm(review_text, customer_name, max_retries=3):\n",
    "    \"\"\"Llama a OpenRouter para analizar una rese√±a\"\"\"\n",
    "    \n",
    "    prompt = crear_prompt_analisis(review_text, customer_name)\n",
    "    \n",
    "    payload = {\n",
    "        \"model\": MODEL,\n",
    "        \"messages\": [\n",
    "            {\"role\": \"system\", \"content\": \"Eres un experto en an√°lisis de rese√±as de viajes. Respondes SOLO con JSON v√°lido.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        \"temperature\": 0.1,  # Baja temperatura para respuestas consistentes\n",
    "        \"max_tokens\": 500\n",
    "    }\n",
    "    \n",
    "    for intento in range(max_retries):\n",
    "        try:\n",
    "            response = requests.post(\n",
    "                OPENROUTER_API_URL,\n",
    "                headers=headers,\n",
    "                json=payload,\n",
    "                timeout=30\n",
    "            )\n",
    "            \n",
    "            if response.status_code == 200:\n",
    "                result = response.json()\n",
    "                content = result['choices'][0]['message']['content']\n",
    "                \n",
    "                # Intentar parsear el JSON\n",
    "                # Limpiar el contenido si viene con markdown\n",
    "                if \"```json\" in content:\n",
    "                    content = content.split(\"```json\")[1].split(\"```\")[0]\n",
    "                elif \"```\" in content:\n",
    "                    content = content.split(\"```\")[1].split(\"```\")[0]\n",
    "                \n",
    "                parsed = json.loads(content.strip())\n",
    "                return parsed\n",
    "            \n",
    "            elif response.status_code == 429:  # Rate limit\n",
    "                time.sleep(2 ** intento)  # Exponential backoff\n",
    "                continue\n",
    "            \n",
    "            else:\n",
    "                print(f\"Error API: {response.status_code} - {response.text}\")\n",
    "                return None\n",
    "                \n",
    "        except json.JSONDecodeError as e:\n",
    "            print(f\"Error parseando JSON: {e}\")\n",
    "            return None\n",
    "        except Exception as e:\n",
    "            print(f\"Error en petici√≥n: {e}\")\n",
    "            if intento < max_retries - 1:\n",
    "                time.sleep(1)\n",
    "    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def procesar_rese√±as_batch(df, batch_size=10, start_index=0):\n",
    "    \"\"\"Procesa las rese√±as en lotes para evitar l√≠mites de rate\"\"\"\n",
    "    \n",
    "    # Filtrar solo rese√±as no analizadas con texto\n",
    "    df_pendientes = df[\n",
    "        (df['analyzed'] == False) & \n",
    "        (df['review_text'].notna()) & \n",
    "        (df['review_text'] != '')\n",
    "    ].iloc[start_index:]\n",
    "    \n",
    "    print(f\"Rese√±as pendientes de analizar: {len(df_pendientes)}\")\n",
    "    \n",
    "    resultados = []\n",
    "    errores = []\n",
    "    \n",
    "    # Procesar en lotes\n",
    "    for i in tqdm(range(0, len(df_pendientes), batch_size), desc=\"Procesando lotes\"):\n",
    "        batch = df_pendientes.iloc[i:i+batch_size]\n",
    "        \n",
    "        for idx, row in batch.iterrows():\n",
    "            # Analizar rese√±a\n",
    "            resultado = analizar_con_llm(\n",
    "                row['review_text'], \n",
    "                row['customer_name']\n",
    "            )\n",
    "            \n",
    "            if resultado:\n",
    "                resultado['index'] = idx\n",
    "                resultados.append(resultado)\n",
    "            else:\n",
    "                errores.append({\n",
    "                    'index': idx,\n",
    "                    'review_id': row['review_id'],\n",
    "                    'error': 'No se pudo analizar'\n",
    "                })\n",
    "            \n",
    "            # Peque√±a pausa entre peticiones\n",
    "            time.sleep(0.5)\n",
    "        \n",
    "        # Pausa m√°s larga entre lotes\n",
    "        print(f\"Lote completado. Esperando antes del siguiente...\")\n",
    "        time.sleep(2)\n",
    "    \n",
    "    return resultados, errores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def guardar_progreso(df, filename_base='trustpilot_analyzed'):\n",
    "    \"\"\"Guarda el progreso del an√°lisis\"\"\"\n",
    "    \n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    filename = f\"{filename_base}_{timestamp}.csv\"\n",
    "    \n",
    "    df.to_csv(filename, index=False, encoding='utf-8-sig')\n",
    "    print(f\"Progreso guardado en: {filename}\")\n",
    "    \n",
    "    # Tambi√©n guardar un backup del √∫ltimo estado\n",
    "    df.to_csv(f\"{filename_base}_latest.csv\", index=False, encoding='utf-8-sig')\n",
    "    \n",
    "    return filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analizar_trustpilot_reviews(csv_path, batch_size=10, max_reviews=None):\n",
    "    \"\"\"Funci√≥n principal para analizar las rese√±as\"\"\"\n",
    "    \n",
    "    # Cargar datos\n",
    "    print(\"üìÇ Cargando datos...\")\n",
    "    df = pd.read_csv(csv_path, encoding='utf-8-sig')\n",
    "    \n",
    "    # Limitar n√∫mero de rese√±as si se especifica\n",
    "    if max_reviews:\n",
    "        df = df.head(max_reviews)\n",
    "    \n",
    "    print(f\"üìä Total de rese√±as a procesar: {len(df)}\")\n",
    "    \n",
    "    # Verificar API key\n",
    "    if not OPENROUTER_API_KEY or OPENROUTER_API_KEY == \"tu-api-key-aqui\":\n",
    "        print(\"‚ùå Error: Configura tu API key de OpenRouter\")\n",
    "        return None\n",
    "    \n",
    "    # Procesar rese√±as\n",
    "    print(\"\\nü§ñ Iniciando an√°lisis con LLM...\")\n",
    "    resultados, errores = procesar_rese√±as_batch(df, batch_size)\n",
    "    \n",
    "    # Actualizar DataFrame\n",
    "    print(f\"\\n‚úÖ An√°lisis completado: {len(resultados)} rese√±as\")\n",
    "    print(f\"‚ùå Errores: {len(errores)} rese√±as\")\n",
    "    \n",
    "    df_actualizado = actualizar_dataframe(df, resultados)\n",
    "    \n",
    "    # Guardar resultados\n",
    "    filename = guardar_progreso(df_actualizado)\n",
    "    \n",
    "    # Mostrar estad√≠sticas\n",
    "    print(\"\\nüìà Estad√≠sticas del an√°lisis:\")\n",
    "    print(f\"- Idiomas detectados: {df_actualizado['language'].value_counts().to_dict()}\")\n",
    "    print(f\"- Sentimientos: {df_actualizado['sentiment'].value_counts().to_dict()}\")\n",
    "    print(f\"- Tipos de turista: {df_actualizado['tourist_type'].value_counts().to_dict()}\")\n",
    "    \n",
    "    return df_actualizado, errores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configurar par√°metros\n",
    "CSV_PATH = \"trustpilot_travel_reviews_20241201_120000.csv\"  # Ajusta el nombre\n",
    "BATCH_SIZE = 10  # Rese√±as por lote\n",
    "MAX_REVIEWS = 100  # None para procesar todas\n",
    "\n",
    "# Ejecutar an√°lisis\n",
    "df_analizado, errores = analizar_trustpilot_reviews(\n",
    "    csv_path=CSV_PATH,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    max_reviews=MAX_REVIEWS\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# Crear visualizaciones b√°sicas\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Configurar estilo\n",
    "plt.style.use('seaborn-v0_8')\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# 1. Distribuci√≥n de sentimientos\n",
    "df_analizado['sentiment'].value_counts().plot(kind='bar', ax=axes[0,0])\n",
    "axes[0,0].set_title('Distribuci√≥n de Sentimientos')\n",
    "\n",
    "# 2. Top 10 temas principales\n",
    "df_analizado['main_topic'].value_counts().head(10).plot(kind='barh', ax=axes[0,1])\n",
    "axes[0,1].set_title('Top 10 Temas Principales')\n",
    "\n",
    "# 3. Tipos de turista\n",
    "df_analizado['tourist_type'].value_counts().plot(kind='pie', ax=axes[1,0])\n",
    "axes[1,0].set_title('Tipos de Turista')\n",
    "\n",
    "# 4. Emociones detectadas\n",
    "df_analizado['emotion'].value_counts().plot(kind='bar', ax=axes[1,1])\n",
    "axes[1,1].set_title('Emociones Detectadas')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
