{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar librer√≠as necesarias\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "from datetime import datetime\n",
    "import os\n",
    "import glob\n",
    "import pickle\n",
    "from typing import Dict, List, Optional, Tuple\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuraci√≥n de API\n",
    "OPENROUTER_API_KEY = \"\"  # ‚ö†Ô∏è A√ëADIR TU API KEY AQU√ç - Obtener de https://openrouter.ai/keys\n",
    "OPENROUTER_API_URL = \"https://openrouter.ai/api/v1/chat/completions\"\n",
    "\n",
    "# Modelo recomendado (puedes cambiar seg√∫n necesidades y presupuesto)\n",
    "MODEL = \"google/gemini-2.5-flash\"  # R√°pido y econ√≥mico\n",
    "# Alternativas: \"openai/gpt-3.5-turbo\", \"meta-llama/llama-3-8b-instruct\"\n",
    "\n",
    "# Headers para las peticiones\n",
    "headers = {\n",
    "    \"Authorization\": f\"Bearer {OPENROUTER_API_KEY}\",\n",
    "    \"Content-Type\": \"application/json\",\n",
    "    \"HTTP-Referer\": \"http://localhost:8888\",  # Requerido por OpenRouter\n",
    "    \"X-Title\": \"TrustPilot Analysis\"\n",
    "}\n",
    "\n",
    "# Definir los campos esperados en la respuesta del modelo (en orden)\n",
    "CAMPOS_ANALISIS = [\n",
    "    \"language\", \"sentiment\", \"sentiment_score\", \"emotion\", \"emotion_intensity\", \"customer_gender\",\n",
    "    \"main_topic\", \"keywords\", \"customer_type\", \"tourist_type\", \"group_type\"\n",
    "]\n",
    "\n",
    "# Variables globales para los nombres de las columnas (se asignar√°n din√°micamente)\n",
    "REVIEW_TEXT_COL = None\n",
    "CUSTOMER_NAME_COL = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar el CSV con las rese√±as\n",
    "df = pd.read_csv('./test.csv', encoding='utf-8-sig')\n",
    "\n",
    "# Limpiar nombres de columnas (quitar espacios extra)\n",
    "df.columns = df.columns.str.strip()\n",
    "\n",
    "# Mostrar todas las columnas para identificar correctamente\n",
    "print(f\"Total de rese√±as: {len(df)}\")\n",
    "print(f\"Columnas en el CSV:\")\n",
    "for i, col in enumerate(df.columns):\n",
    "    print(f\"  {i}: '{col}' (longitud: {len(col)})\")\n",
    "\n",
    "# Buscar la columna de review_text (puede tener nombre ligeramente diferente)\n",
    "texto_columnas = [col for col in df.columns if 'review' in col.lower() and 'text' in col.lower()]\n",
    "nombre_columnas = [col for col in df.columns if 'customer' in col.lower() and 'name' in col.lower()]\n",
    "\n",
    "print(f\"\\nColumnas que contienen 'review' y 'text': {texto_columnas}\")\n",
    "print(f\"Columnas que contienen 'customer' y 'name': {nombre_columnas}\")\n",
    "\n",
    "# Si encontramos las columnas, proceder con la limpieza\n",
    "if texto_columnas and nombre_columnas:\n",
    "    # Asignar variables globales\n",
    "    REVIEW_TEXT_COL = texto_columnas[0]\n",
    "    CUSTOMER_NAME_COL = nombre_columnas[0]\n",
    "    \n",
    "    print(f\"\\nUsando columnas:\")\n",
    "    print(f\"- Texto de rese√±a: '{REVIEW_TEXT_COL}'\")\n",
    "    print(f\"- Nombre del cliente: '{CUSTOMER_NAME_COL}'\")\n",
    "    \n",
    "    # Limpiar datos: eliminar filas con review_text vac√≠o o nulo\n",
    "    df_original_len = len(df)\n",
    "    df = df.dropna(subset=[REVIEW_TEXT_COL])  # Eliminar filas con texto nulo\n",
    "    df = df[df[REVIEW_TEXT_COL].astype(str).str.strip() != '']  # Eliminar filas con texto vac√≠o\n",
    "    \n",
    "    print(f\"\\nLimpieza de datos:\")\n",
    "    print(f\"- Rese√±as originales: {df_original_len}\")\n",
    "    print(f\"- Rese√±as despu√©s de limpieza: {len(df)}\")\n",
    "    print(f\"- Rese√±as eliminadas: {df_original_len - len(df)}\")\n",
    "    \n",
    "    # Inicializar la columna 'analyzed' si no existe\n",
    "    if 'analyzed' not in df.columns:\n",
    "        df['analyzed'] = False\n",
    "        \n",
    "    print(f\"- Rese√±as ya analizadas: {df['analyzed'].sum()}\")\n",
    "    print(f\"- Rese√±as pendientes de analizar: {(df['analyzed'] == False).sum()}\")\n",
    "    \n",
    "else:\n",
    "    print(\"\\n‚ùå No se encontraron las columnas de texto de rese√±a o nombre del cliente\")\n",
    "    print(\"Por favor revisa el archivo CSV\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crear_prompt_analisis(review_text, customer_name):\n",
    "    \"\"\"Crea el prompt para analizar una rese√±a\"\"\"\n",
    "    \n",
    "    prompt = f\"\"\"\n",
    "Eres un analizador especializado en evaluaci√≥n de rese√±as tur√≠sticas y an√°lisis de sentimientos. Para cada texto que recibas, deber√°s analizar y proporcionar la siguiente informaci√≥n separada por el delimitador \"|\":\n",
    "\n",
    "RESE√ëA A ANALIZAR:\n",
    "Texto: {review_text}\n",
    "Cliente: {customer_name}\n",
    "\n",
    "AN√ÅLISIS REQUERIDO (responde cada campo separado por \"|\"):\n",
    "\n",
    "0. Language: Clasifica como \"es\", \"en\", \"fr\", \"de\", \"it\", \"pt\", \"nl\", \"ru\", \"tr\", \"ar\", \"zh\", \"ja\", \"ko\", \"other\"\n",
    "1. Sentiment: Clasifica como \"Positivo\", \"Negativo\" o \"Neutro\"\n",
    "2. Sentiment_score: Eval√∫a en escala de -1 a +1 (-1=extremadamente negativo, 0=neutro, +1=extremadamente positivo)\n",
    "3. Emotion: Identifica una emoci√≥n (joy, surprise, neutral, sadness, disgust, anger, fear)\n",
    "4. Emotion_intensity: Intensidad de 1-5 (1=muy leve, 5=muy intensa)\n",
    "5. Customer_gender: Basado en el nombre (masculino, femenino, unknown)\n",
    "6. Topic: Tema principal (Atenci√≥n al cliente, Limpieza, Instalaciones, Relaci√≥n calidad-precio, Servicios, Ubicaci√≥n, √âtica y sostenibilidad, Check-in y Check-out, Comodidad y descanso, Oferta gastron√≥mica, Facilidad de reserva y accesibilidad digital, Animaci√≥n y actividades, Seguridad)\n",
    "7. Keywords: 3-5 t√©rminos relevantes separados por comas SIN espacios\n",
    "8. Customer_type: Promotor, Leal, Neutral, Cr√≠tico, Oportunista\n",
    "9. Tourist_type: Turista de ocio, cultural, naturaleza, aventura, compras, espiritual/religioso, gastron√≥mico, deportivo, wellness, solidario/voluntario\n",
    "10. Group_type: familiar, amigos, pareja, solitario, grupo organizado\n",
    "\n",
    "FORMATO DE RESPUESTA:\n",
    "Responde √öNICAMENTE con los valores separados por \"|\" en el orden exacto listado arriba.\n",
    "Si no puedes determinar alg√∫n campo, usa \"unknown\".\n",
    "NO incluyas espacios antes o despu√©s de los pipes.\n",
    "\n",
    "Ejemplo: Positivo|0.8|joy|4|femenino|Atenci√≥n al cliente|excelente,servicio,amable|Promotor|Turista de ocio|pareja\n",
    "\"\"\"\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analizar_con_llm(review_text, customer_name, max_retries=3):\n",
    "    \"\"\"Llama a OpenRouter para analizar una rese√±a\"\"\"\n",
    "    \n",
    "    prompt = crear_prompt_analisis(review_text, customer_name)\n",
    "    \n",
    "    payload = {\n",
    "        \"model\": MODEL,\n",
    "        \"messages\": [\n",
    "            {\"role\": \"system\", \"content\": \"Eres un experto en an√°lisis de rese√±as de viajes. Respondes SOLO con los valores separados por |.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        \"temperature\": 0.1,  # Baja temperatura para respuestas consistentes\n",
    "        \"max_tokens\": 500\n",
    "    }\n",
    "    \n",
    "    for intento in range(max_retries):\n",
    "        try:\n",
    "            response = requests.post(\n",
    "                OPENROUTER_API_URL,\n",
    "                headers=headers,\n",
    "                json=payload,\n",
    "                timeout=30\n",
    "            )\n",
    "            \n",
    "            if response.status_code == 200:\n",
    "                result = response.json()\n",
    "                content = result['choices'][0]['message']['content']\n",
    "                \n",
    "                print(f\"Respuesta del modelo: {content}\")  # Para depuraci√≥n\n",
    "                \n",
    "                if not content.strip():\n",
    "                    print(\"Respuesta vac√≠a de la API\")\n",
    "                    return None\n",
    "                \n",
    "                # Limpiar posibles markdown o espacios extra\n",
    "                if \"```\" in content:\n",
    "                    # Extraer contenido entre markdown\n",
    "                    lines = content.split('\\n')\n",
    "                    for line in lines:\n",
    "                        if '|' in line and not line.strip().startswith('```'):\n",
    "                            content = line.strip()\n",
    "                            break\n",
    "                \n",
    "                content = content.strip()\n",
    "                \n",
    "                # Dividir por el delimitador pipe\n",
    "                valores = [v.strip() for v in content.split(\"|\")]\n",
    "                \n",
    "                # Verificar que tenemos el n√∫mero correcto de campos\n",
    "                if len(valores) != len(CAMPOS_ANALISIS):\n",
    "                    print(f\"La respuesta no tiene el n√∫mero correcto de campos: {len(valores)} vs {len(CAMPOS_ANALISIS)}\")\n",
    "                    print(f\"Valores recibidos: {valores}\")\n",
    "                    return None\n",
    "                \n",
    "                # Crear diccionario con los resultados\n",
    "                resultado = dict(zip(CAMPOS_ANALISIS, valores))\n",
    "                return resultado\n",
    "            \n",
    "            elif response.status_code == 429:  # Rate limit\n",
    "                time.sleep(2 ** intento)  # Exponential backoff\n",
    "                continue\n",
    "            \n",
    "            else:\n",
    "                print(f\"Error API: {response.status_code} - {response.text}\")\n",
    "                return None\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Error en petici√≥n: {e}\")\n",
    "            if intento < max_retries - 1:\n",
    "                time.sleep(1)\n",
    "    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def procesar_rese√±as_batch(df, batch_size=10, start_index=0):\n",
    "    \"\"\"Procesa las rese√±as en lotes para evitar l√≠mites de rate\"\"\"\n",
    "    \n",
    "    global REVIEW_TEXT_COL, CUSTOMER_NAME_COL\n",
    "    \n",
    "    if REVIEW_TEXT_COL is None or CUSTOMER_NAME_COL is None:\n",
    "        print(\"‚ùå Error: Las columnas de texto y nombre no han sido identificadas\")\n",
    "        return [], []\n",
    "    \n",
    "    # Filtrar solo rese√±as no analizadas (ya limpiamos los datos vac√≠os en la carga)\n",
    "    df_pendientes = df[df['analyzed'] == False].iloc[start_index:]\n",
    "    \n",
    "    print(f\"Rese√±as pendientes de analizar: {len(df_pendientes)}\")\n",
    "    \n",
    "    resultados = []\n",
    "    errores = []\n",
    "    \n",
    "    # Procesar en lotes\n",
    "    for i in tqdm(range(0, len(df_pendientes), batch_size), desc=\"Procesando lotes\"):\n",
    "        batch = df_pendientes.iloc[i:i+batch_size]\n",
    "        \n",
    "        for idx, row in batch.iterrows():\n",
    "            # Analizar rese√±a usando nombres de columnas din√°micos\n",
    "            resultado = analizar_con_llm(\n",
    "                row[REVIEW_TEXT_COL], \n",
    "                row[CUSTOMER_NAME_COL]\n",
    "            )\n",
    "            \n",
    "            if resultado:\n",
    "                resultado['index'] = idx\n",
    "                resultados.append(resultado)\n",
    "            else:\n",
    "                errores.append({\n",
    "                    'index': idx,\n",
    "                    'review_id': row.get('review_id', 'N/A'),\n",
    "                    'error': 'No se pudo analizar'\n",
    "                })\n",
    "            \n",
    "            # Peque√±a pausa entre peticiones\n",
    "            time.sleep(0.5)\n",
    "        \n",
    "        # Pausa m√°s larga entre lotes\n",
    "        print(f\"Lote completado. Esperando antes del siguiente...\")\n",
    "        time.sleep(2)\n",
    "    \n",
    "    return resultados, errores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def actualizar_dataframe(df, resultados):\n",
    "    \"\"\"Actualiza el DataFrame con los resultados del an√°lisis\"\"\"\n",
    "    \n",
    "    # Inicializar las columnas si no existen\n",
    "    for campo in CAMPOS_ANALISIS:\n",
    "        if campo not in df.columns:\n",
    "            df[campo] = None\n",
    "    \n",
    "    # Agregar columna 'analyzed' si no existe\n",
    "    if 'analyzed' not in df.columns:\n",
    "        df['analyzed'] = False\n",
    "    \n",
    "    # Actualizar con los resultados\n",
    "    for resultado in resultados:\n",
    "        idx = resultado['index']\n",
    "        \n",
    "        # Actualizar cada campo\n",
    "        for campo in CAMPOS_ANALISIS:\n",
    "            if campo in resultado:\n",
    "                df.loc[idx, campo] = resultado[campo]\n",
    "        \n",
    "        # Marcar como analizado\n",
    "        df.loc[idx, 'analyzed'] = True\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def guardar_progreso(df, filename_base='trustpilot_analyzed'):\n",
    "    \"\"\"Guarda el progreso del an√°lisis\"\"\"\n",
    "    \n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    filename = f\"{filename_base}_{timestamp}.csv\"\n",
    "    \n",
    "    df.to_csv(filename, index=False, encoding='utf-8-sig')\n",
    "    print(f\"Progreso guardado en: {filename}\")\n",
    "    \n",
    "    # Tambi√©n guardar un backup del √∫ltimo estado\n",
    "    df.to_csv(f\"{filename_base}_latest.csv\", index=False, encoding='utf-8-sig')\n",
    "    \n",
    "    return filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analizar_trustpilot_reviews(csv_path, batch_size=10, max_reviews=None):\n",
    "    \"\"\"Funci√≥n principal para analizar las rese√±as\"\"\"\n",
    "    \n",
    "    # Cargar datos\n",
    "    print(\"üìÇ Cargando datos...\")\n",
    "    df = pd.read_csv(csv_path, encoding='utf-8-sig')\n",
    "    \n",
    "    # Limitar n√∫mero de rese√±as si se especifica\n",
    "    if max_reviews:\n",
    "        df = df.head(max_reviews)\n",
    "    \n",
    "    print(f\"üìä Total de rese√±as a procesar: {len(df)}\")\n",
    "    \n",
    "    # Verificar API key\n",
    "    if not OPENROUTER_API_KEY or OPENROUTER_API_KEY == \"tu-api-key-aqui\":\n",
    "        print(\"‚ùå Error: Configura tu API key de OpenRouter\")\n",
    "        return None\n",
    "    \n",
    "    # Procesar rese√±as\n",
    "    print(\"\\nü§ñ Iniciando an√°lisis con LLM...\")\n",
    "    resultados, errores = procesar_rese√±as_batch(df, batch_size)\n",
    "    \n",
    "    # Actualizar DataFrame\n",
    "    print(f\"\\n‚úÖ An√°lisis completado: {len(resultados)} rese√±as\")\n",
    "    print(f\"‚ùå Errores: {len(errores)} rese√±as\")\n",
    "    \n",
    "    df_actualizado = actualizar_dataframe(df, resultados)\n",
    "    \n",
    "    # Guardar resultados\n",
    "    filename = guardar_progreso(df_actualizado)\n",
    "    \n",
    "    # Mostrar estad√≠sticas\n",
    "    print(\"\\nüìà Estad√≠sticas del an√°lisis:\")\n",
    "    if 'sentiment' in df_actualizado.columns:\n",
    "        print(f\"- Sentimientos: {df_actualizado['sentiment'].value_counts().to_dict()}\")\n",
    "    if 'main_topic' in df_actualizado.columns:\n",
    "        print(f\"- Temas principales: {df_actualizado['main_topic'].value_counts().to_dict()}\")\n",
    "    if 'tourist_type' in df_actualizado.columns:\n",
    "        print(f\"- Tipos de turista: {df_actualizado['tourist_type'].value_counts().to_dict()}\")\n",
    "    if 'emotion' in df_actualizado.columns:\n",
    "        print(f\"- Emociones: {df_actualizado['emotion'].value_counts().to_dict()}\")\n",
    "    \n",
    "    return df_actualizado, errores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configurar par√°metros\n",
    "CSV_PATH = \"./test.csv\"  # Ajusta el nombre\n",
    "BATCH_SIZE = 10  # Rese√±as por lote\n",
    "MAX_REVIEWS = 100  # None para procesar todas\n",
    "\n",
    "# Ejecutar an√°lisis\n",
    "df_analizado, errores = analizar_trustpilot_reviews(\n",
    "    csv_path=CSV_PATH,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    max_reviews=MAX_REVIEWS\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# Crear visualizaciones b√°sicas\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Solo ejecutar si df_analizado existe y tiene datos analizados\n",
    "if 'df_analizado' in locals() and df_analizado is not None:\n",
    "    # Configurar estilo\n",
    "    plt.style.use('seaborn-v0_8')\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "    # 1. Distribuci√≥n de sentimientos\n",
    "    if 'sentiment' in df_analizado.columns:\n",
    "        df_analizado['sentiment'].value_counts().plot(kind='bar', ax=axes[0,0])\n",
    "        axes[0,0].set_title('Distribuci√≥n de Sentimientos')\n",
    "    \n",
    "    # 2. Top 10 temas principales\n",
    "    if 'main_topic' in df_analizado.columns:\n",
    "        df_analizado['main_topic'].value_counts().head(10).plot(kind='barh', ax=axes[0,1])\n",
    "        axes[0,1].set_title('Top 10 Temas Principales')\n",
    "    \n",
    "    # 3. Tipos de turista\n",
    "    if 'tourist_type' in df_analizado.columns:\n",
    "        df_analizado['tourist_type'].value_counts().plot(kind='pie', ax=axes[1,0])\n",
    "        axes[1,0].set_title('Tipos de Turista')\n",
    "    \n",
    "    # 4. Emociones detectadas\n",
    "    if 'emotion' in df_analizado.columns:\n",
    "        df_analizado['emotion'].value_counts().plot(kind='bar', ax=axes[1,1])\n",
    "        axes[1,1].set_title('Emociones Detectadas')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No hay datos analizados para visualizar. Ejecuta primero el an√°lisis.\")\n",
    "\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
